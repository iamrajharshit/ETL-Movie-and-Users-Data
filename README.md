# ğŸ¬ ETL Pipeline with Apache Airflow

This project implements an automated **ETL (Extract, Transform, Load)** pipeline using **Apache Airflow** to process **movie and user datasets**. The pipeline is designed to run on a scheduled basis and is fully orchestrated using Airflow DAGs.

---

## ğŸš€ Features

- âœ… Extraction of raw movie and user data (CSV or API supported)
- ğŸ”„ Transformation of data (cleaning, filtering, formatting)
- ğŸ“¦ Loading into a data warehouse or database (e.g., PostgreSQL, SQLite)
- ğŸ•“ Scheduled execution using Airflow DAGs
- ğŸ“Š Monitoring and logging of each task in the pipeline

---

## ğŸ› ï¸ Tech Stack

- **Apache Airflow** â€“ Workflow orchestration
- **Python** â€“ Data processing
- **Pandas** â€“ Data transformation
- **SQLAlchemy / PostgreSQL / SQLite** â€“ Database support
- **Docker (Optional)** â€“ For containerized deployment

---

## ğŸ“ Project Structure
```
etl-airflow/
â”‚
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ etl_pipeline.py # Main Airflow DAG definition
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ movies.csv # Sample movie data
â”‚ â””â”€â”€ users.csv # Sample user data
â”‚
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ extract.py # Extraction logic
â”‚ â””â”€â”€ transform.py # Transformation logic
â”‚ â””â”€â”€ load.py # Loading logic
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation

```
